---
type: post
title: "О важности логов"
Slug: "on-the-importance-of-logs"
date: "2014-05-20"
tags: 
  - "logging"
  - "amazon"
  - "aws"
---

Я решил возродить свой русскоязычный блог. Напомню, что старый находится по адресу [http://hrafn.me](http://hrafn.me) и уже больше года не обновляется. Ранее я предполагал, что буду стараться периодически писать только в свой англоязычный ([http://alxschwarz.com](http://alxschwarz.com)), но поскольку часто встречаются интересные, на мой взгляд, статьи на английском, я подумал, что надо все же писать что-то и на родном языке. Размещать предполагаю, по большей части, переводы, так что отличий от старого блога будет не так и много.

Итак, в этом посте я хочу предложить вашему вниманию перевод статьи от Chris Munns (AWS Solutions Architect). Анализ логов весьма полезная вещь, но, как я заметил, многие частенько забывают про это. Это просто попытка напомнить. 

Ссылка на оригинал: [https://medium.com/aws-activate-startup-blog/72afccab49d7](https://medium.com/aws-activate-startup-blog/72afccab49d7).

### Вступление

Как Solutions Architect в Amazon Web Services я работаю со множеством стартапов, помогая им в строительстве, развертывании, управлении и росте инфраструктуры на платформе AWS. На встрече с новой компанией, первый вопрос, который я задаю: "Что вы делаете с логами?". Чаще всего ответ означает фактически "ничего". Большая часть опрошенных периодически проверяет, что логи не заполняют все доступные пространство на дисках. Некоторые собирают логи, но никак не отслеживают их содержимое и не мониторят. А большинство хранят данные логов не более нескольких дней, в лучшем случае.

Однако, есть компании, которые делают правильные вещи и понимают значение агрегирования, анализа и хранения столь чрезвычайно важных данных о работе системы.

Итак, что вы делаете с вашими логами?

### Важность логов

Данные логов содержат часть крайне ценной необработанной информации об инфраструктуре и приложениях, которую можно обрабатывать и анализировать. Эти данные генерирует операционная система, кроме того, например, веб-сервер, приложения, базы данных и т.д. Среди кучи бессмысленных строк, казалось бы, случайного текста могут быть подсказки о производительности, безопасности, ошибках в коде, моделях доступа и другие данные о работе. Но пользователи AWS используют эти данные также по другим причинам, например, для создания рекомендаций о продуктах, выполнения A/B тестов для дизайна веб-сайта, отслеживания взаимодействия с пользователями и доставки целевой рекламы конечным пользователям.

Без соответствующих инструментов, поиск этой информации может превратиться в поиск иголки в стогу сена. Но при использовании правильных практик логи могут стать источником №1 для бизнес-информации и информации о работе системы. Сохранение и предоставление к ней доступа внутри компании может стать невероятно важным. 

### Разновидности логов

Инфраструктура может иметь множество источников логов:

**Логи операционной системы:** Часть основной информации о том, что делает операционная система. Умерли ли процессы? Запустились ли они? Что-то вызвало нехватку ресурсов? Отказ "железа"? В зависимости от ОС, операционная система может предложить огромное количество информации.

**Логи веб-сервера:** Apache, Nginx, IIS и другие сервисы предоставляют тонны информации о запросах и состоянии самого сервера. Есть ли ошибки в коде, с которыми обработчик не может справиться? Кто-то пытался получить доступ к данным, которые отсутствуют, или которых там вообще не должно было быть? Кто-то активно пытается просканировать веб-сервер на предмет наличия уязвимостей? Как обрабатывается страница? Множество основной и дополнительной информации может быть найдено в логах веб-сервера, делая часть из них крайне важными.

**Логи приложений:** Создание логов - возможность, которую можно включить при написании собственного приложения, или она может быть уже включена в приложении, которое используется. Приложение имеет сложности с подключением к базе данных? Как быстро направляются запросы? Почему приложение "рухнуло"? Что приводит к показу пользователю сообщения об ошибке? Часто логи приложений стоят на первом месте при поиске источника проблем, которые испытывают пользователи, что делает логи крайне важным источником информации.

**Логи базы данных:** Медленные запросы? Проблемы со стабильностью? Падение? Все запросы? Логи базы данных потенциально предоставляют доступ ко всей этой информации.

**Логи CDN:** Большая часть CDN предоставляет логи, подобные логам веб-сервера. Они могут быть очень полезны при анализе использования сайта, создании рекомендаций и т.д.

### Логи Amazon Web Service

Множество различных сервисов AWS генерируют логи и предоставляют к ним доступ. Часто эти логи логи хранятся в виде файлов на Amazon S3, если выбран этот вариант, или доступны через API самого сервиса или через веб-консоль. Вот список сервисов Amazon, которые на данный момент предоставляют доступ к логам:

- [Amazon S3 Access](http://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html)
- [Amazon CloudFront Access](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html)
- [Elastic Load Balancer (ELB)](http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/access-log-collection.html)
- [Amazon Relational Database Service (RDS)](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Procedural.Downloading.html)
- [Amazon Elastic MapReduce (EMR)](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-manage-view-web-log-files.html)
- [Amazon Redshift](http://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html)
- [AWS Elastic Beanstalk](http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.loggingS3.title.html)
- [AWS OpsWorks](http://docs.aws.amazon.com/opsworks/latest/userguide/troubleshoot-debug-log.html) (или эта [ссылка](http://docs.aws.amazon.com/opsworks/latest/userguide/agent-show.html))
- [AWS Import/Export](http://docs.aws.amazon.com/AWSImportExport/latest/DG/ViewingLogFilesImportJob.html)
- [AWS Data Pipeline](http://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/dp-error-logs.html)
- [AWS CloudTrail](https://aws.amazon.com/cloudtrail/)

Последний из списка, CloudTrail, записывает вызовы API для аккаунта и отправляет эти данные владельцу аккаунта. С большой вероятностью стоит включить его для своего аккаунта.

Если хочется быть уверенным в постоянном контроле за данными логов, храните их на долговременном хранилище Amazon Glacier. Время хранения может меняться в зависимости от требований бизнеса. Для определения его используйте [управление жизненным циклом объекта](http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html) S3.

### Инструменты для анализа логов

Теперь логи хранятся централизованно и в одном месте, что дальше? Хранение этих данных и неиспользование их для анализа не поможет пониманию операционных процессов. Необходим инструмент, который поможет справиться с горой информации. Это может быть инструмент, специально созданных для анализа логов, или это может быть что-то совсем простое, вроде автоматизации хранения данных с использованием сервисов Amazon Redshift, Elastic MapReduce (EMR) и Data Pipeline для получения ежедневных аналитических отчетов. Многие компании комбинируют эти сервисы в течении долгого времени, поскольку находят все больше и больше вариантов использования информации, предоставляемой логами. 

Как бы то ни было, нужно найти инструмент, который предложит гибкость, адекватную стоимость и масштабируемость. Вот лишь несколько примеров:

**SaaS решения**
- [Boundary](http://boundary.com/)
- [Loggly](http://www.loggly.com/)
- [Papertrail](http://papertrailapp.com/)
- [Splunk Storm](http://www.splunkstorm.com/)
- [SumoLogic](http://www.sumologic.com/)

**Open Source решения**
- [Graylog2](http://graylog2.org/)
- [LogStash + Kibana + ElasticSearch](http://www.elasticsearch.org/overview/logstash/)
- [Log.io](http://logio.org/)

**Enterprise решения**
- [Logscape](http://www.logscape.com/)
- [Splunk](http://www.splunk.com/)
- [Tibco LogLogic](http://www.tibco.com/products/event-processing/log-management/default.jsp)

В качестве примера анализа логов в AWS с использованием Amazon EMR, посмотрите эти два наших великолепных руководства:

- [Analyze Log Data with Apache Hive, Windows PowerShell, and Amazon EMR](https://aws.amazon.com/articles/3681655242374956)
- [Analyze Elastic Load Balancing Log Data](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-process-logs.html)

### Начинаем действовать

О логах и их анализе можно долго разговаривать. Будем надеяться, мне удалось донести мысль о том, что если вы не сохраняете логи и не следите за ними, вы многое теряете. Желательно найти время и возможности и начать обработку этих крайне важных и ценных данных. Как уже упоминалось, существует множество источников логов и огромное количество инструментов для их анализа. Объединение данных и инструментов может принести плоды как для получение оперативной информации, так и для получения дополнительных возможностей для развития бизнеса. 


